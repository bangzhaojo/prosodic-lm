{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0def04-3121-42b9-af41-43f37c8f5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9246ec64-a030-4495-8645-83948175dea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/shared/3/projects/bangzhao/.hf_cache\"\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1269863-1dd8-4812-bf42-57991fc09309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 17:55:30.442207: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753206930.457336 3178664 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753206930.462059 3178664 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753206930.476701 3178664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753206930.476712 3178664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753206930.476713 3178664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753206930.476715 3178664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-22 17:55:30.481186: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import *\n",
    "from tokenizers import *\n",
    "\n",
    "from bertPhoneme import BertEmbeddingsV2, BertModelV2, BertForMaskedLMV2, BertConfigV2, MaskedLMWithProsodyOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c72171e-21e2-4d69-a215-4ff3871dbe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc1e7ec1-5626-493a-9050-b422ea2dbdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/shared/3/projects/bangzhao/prosodic_embeddings/merge/training_data/output_part_1.jsonl\"\n",
    "phonemes = set()\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 5000:\n",
    "            break\n",
    "        phonemes.update(set(json.loads(line)['phoneme']))\n",
    "    print(len(phonemes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "691b952e-554d-4235-b331-de4da37ca8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes.update(['UNK', 'SIL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e602f1-9590-4cb4-9f42-805508a859c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_vocab = {p: i for i, p in enumerate(phonemes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4abb52c-3b70-4419-9011-19c696bb31d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NG': 0, 'UH0': 1, 'S': 2, 'EY2': 3, 'EY1': 4, 'AE1': 5, 'OY1': 6, 'ER1': 7, 'SIL': 8, 'W': 9, 'JH': 10, 'UNK': 11, 'AA0': 12, 'B': 13, 'SH': 14, 'DH': 15, 'EH2': 16, 'AW2': 17, 'UH2': 18, 'AH0': 19, 'AH2': 20, 'AO2': 21, 'IY2': 22, 'IH0': 23, 'EY0': 24, 'OY2': 25, 'IH1': 26, 'Z': 27, 'TH': 28, 'AY2': 29, 'T': 30, 'OW0': 31, 'OY0': 32, 'spn': 33, 'P': 34, 'HH': 35, 'OW2': 36, 'K': 37, 'AE0': 38, 'OW1': 39, 'G': 40, 'M': 41, 'R': 42, 'N': 43, 'UW2': 44, 'AY0': 45, 'ER0': 46, 'AE2': 47, 'AA1': 48, 'F': 49, 'ZH': 50, 'UW1': 51, 'Y': 52, 'AW1': 53, 'D': 54, 'AY1': 55, 'L': 56, 'EH0': 57, 'AA2': 58, 'AW0': 59, 'AO0': 60, 'IY1': 61, 'UW0': 62, 'EH1': 63, 'ER2': 64, 'UH1': 65, 'IY0': 66, 'AH1': 67, 'AO1': 68, 'CH': 69, 'IH2': 70, 'V': 71}\n"
     ]
    }
   ],
   "source": [
    "print(phoneme_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c403dc3-7c84-4c7c-b50c-fd1db50a124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_vocab_size = len(phoneme_vocab)\n",
    "mask_token_id = phoneme_vocab[\"SIL\"]\n",
    "pad_token_id = 72\n",
    "pad_cluster_id = 201\n",
    "mask_prosody_id = 200\n",
    "\n",
    "\n",
    "class HuggingFacePhonemeDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, vocab, mask_prob=0.15, max_length=512):\n",
    "        self.dataset = hf_dataset\n",
    "        self.vocab = vocab\n",
    "        self.mask_prob = mask_prob\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataset[idx]\n",
    "\n",
    "        phonemes = sample[\"phoneme\"]\n",
    "        prosody_ids = sample[\"prosody_id_200\"]\n",
    "\n",
    "        input_ids = [self.vocab.get(p, self.vocab[\"UNK\"]) for p in phonemes][:self.max_length]\n",
    "        prosody_ids = prosody_ids[:self.max_length]\n",
    "\n",
    "        labels = input_ids.copy()\n",
    "        prosody_labels = prosody_ids.copy()\n",
    "        for i in range(len(input_ids)):\n",
    "            if random.random() < self.mask_prob:\n",
    "                labels[i] = input_ids[i]\n",
    "                input_ids[i] = self.vocab[\"SIL\"]\n",
    "                prosody_labels[i] = prosody_ids[i]\n",
    "                prosody_ids[i] = 200\n",
    "            else:\n",
    "                labels[i] = -100\n",
    "                prosody_labels[i] = -100\n",
    "\n",
    "        pad_length = self.max_length - len(input_ids)\n",
    "        input_ids.extend([pad_token_id] * pad_length)\n",
    "        labels.extend([-100] * pad_length)\n",
    "        prosody_ids.extend([pad_cluster_id] * pad_length)\n",
    "        prosody_labels.extend([-100] * pad_length)\n",
    "        attention_mask = [1] * (self.max_length - pad_length) + [0] * pad_length\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "            \"prosody_ids\": torch.tensor(prosody_ids, dtype=torch.long),\n",
    "            \"prosody_labels\": torch.tensor(prosody_labels, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b1f0459-c036-4a1c-8a6e-47de4d38aa5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8bc58dab82450a9d15dbc4b0efa549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_dataset = load_dataset(\"json\", data_files=\"/shared/3/projects/bangzhao/prosodic_embeddings/merge/training_data/output_part_1.jsonl\", split=\"train\")\n",
    "hf_dataset = hf_dataset.select(range(49000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ca94bbc-1c05-42c6-baf8-25be3fec747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HuggingFacePhonemeDataset(hf_dataset, phoneme_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4261f08a-8c9d-4d70-b67c-7608045fe1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fbbbaf0-b9da-4649-be17-47904851752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = phoneme_vocab_size\n",
    "phoneme_vocab_size = len(phoneme_vocab)\n",
    "max_length = 512\n",
    "\n",
    "\n",
    "model_config = BertConfigV2(\n",
    "    vocab_size=vocab_size+1,\n",
    "    pad_token_id=pad_token_id,\n",
    "    pad_cluster_id=201,\n",
    "    hidden_size=128,\n",
    "    num_hidden_layers=2,\n",
    "    num_attention_heads=2,\n",
    "    intermediate_size=512,\n",
    "    max_position_embeddings=max_length,\n",
    "    prosody_cluster_size=200 + 2\n",
    ")\n",
    "\n",
    "model = BertForMaskedLMV2(config=model_config)\n",
    "\n",
    "# BERT-Base\t768\t12\t12\t3072\n",
    "# BERT-Small 512\t4\t8\t2048\n",
    "# BERT-Mini\t256\t4\t4\t1024\n",
    "# BERT-Tiny\t128\t2\t2\t512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74f0028c-cbbb-418d-a55a-c783e30472b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLMV2(\n",
       "  (bert): BertModelV2(\n",
       "    (embeddings): BertEmbeddingsV2(\n",
       "      (word_embeddings): Embedding(73, 128, padding_idx=72)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (prosody_embeddings): Embedding(202, 128, padding_idx=201)\n",
       "      (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=128, out_features=73, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (prosody_head): Linear(in_features=128, out_features=202, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53cef04b-4a26-46aa-a4be-344ff7a9a255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 starting...\n",
      "\n",
      "  Step  100 | Avg Loss: 7.7207\n",
      "  Step  200 | Avg Loss: 7.4372\n",
      "  Step  300 | Avg Loss: 7.2869\n",
      "  Step  400 | Avg Loss: 7.1877\n",
      "  Step  500 | Avg Loss: 7.1178\n",
      "  Step  600 | Avg Loss: 7.0637\n",
      "  Step  700 | Avg Loss: 7.0214\n",
      "  Step  800 | Avg Loss: 6.9855\n",
      "  Step  900 | Avg Loss: 6.9540\n",
      "  Step 1000 | Avg Loss: 6.9291\n",
      "  Step 1100 | Avg Loss: 6.9061\n",
      "  Step 1200 | Avg Loss: 6.8867\n",
      "  Step 1300 | Avg Loss: 6.8677\n",
      "  Step 1400 | Avg Loss: 6.8510\n",
      "  Step 1500 | Avg Loss: 6.8356\n",
      "\n",
      " Epoch 1 completed. Avg Loss: 6.8310\n",
      "\n",
      " Epoch 2 starting...\n",
      "\n",
      "  Step  100 | Avg Loss: 6.6188\n",
      "  Step  200 | Avg Loss: 6.6098\n",
      "  Step  300 | Avg Loss: 6.6056\n",
      "  Step  400 | Avg Loss: 6.6009\n",
      "  Step  500 | Avg Loss: 6.5975\n",
      "  Step  600 | Avg Loss: 6.5922\n",
      "  Step  700 | Avg Loss: 6.5895\n",
      "  Step  800 | Avg Loss: 6.5863\n",
      "  Step  900 | Avg Loss: 6.5836\n",
      "  Step 1000 | Avg Loss: 6.5795\n",
      "  Step 1100 | Avg Loss: 6.5759\n",
      "  Step 1200 | Avg Loss: 6.5728\n",
      "  Step 1300 | Avg Loss: 6.5692\n",
      "  Step 1400 | Avg Loss: 6.5654\n",
      "  Step 1500 | Avg Loss: 6.5611\n",
      "\n",
      " Epoch 2 completed. Avg Loss: 6.5596\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "\n",
    "mlm_loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "prosody_loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "num_epochs = 2\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    print(f\"\\n Epoch {epoch + 1} starting...\\n\")\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        prosody_ids = batch[\"prosody_ids\"].to( device)\n",
    "        prosody_labels = batch[\"prosody_labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, prosody_ids=prosody_ids)\n",
    "\n",
    "        mlm_loss = mlm_loss_fn(outputs.logits.view(-1, model.config.vocab_size), labels.view(-1))\n",
    "        prosody_loss = prosody_loss_fn(outputs.prosody_logits.view(-1, model.config.prosody_cluster_size), prosody_labels.view(-1))\n",
    "\n",
    "        total_batch_loss = mlm_loss + prosody_loss\n",
    "        total_batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += total_batch_loss.item()\n",
    "\n",
    "        # Report every 100 steps\n",
    "        if (step + 1) % 100 == 0:\n",
    "            avg_loss = total_loss / (step + 1)\n",
    "            print(f\"  Step {step + 1:>4} | Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    avg_epoch_loss = total_loss / len(train_loader)\n",
    "    print(f\"\\n Epoch {epoch + 1} completed. Avg Loss: {avg_epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70c92476-b063-406f-8521-9b8dcfe13934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1677d837d34c4a5cab72b0a77a00776f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hf_dataset_full = load_dataset(\n",
    "#     \"json\",\n",
    "#     data_files=\"/shared/3/projects/bangzhao/prosodic_embeddings/merge/training_data/output_part_1.jsonl\",\n",
    "#     split=\"train\"\n",
    "# )\n",
    "\n",
    "hf_dataset = load_dataset(\"json\", data_files=\"/shared/3/projects/bangzhao/prosodic_embeddings/merge/training_data_6features/output_part_1_20kSample.jsonl\", split=\"train\")\n",
    "# hf_test_dataset = hf_dataset_full.select(range(49000, 50000))\n",
    "hf_dataset_test = hf_dataset.select(range(19900, 20000))\n",
    "\n",
    "# === Step 2: Wrap the dataset with HuggingFacePhonemeDataset ===\n",
    "# test_dataset = HuggingFacePhonemeDataset(\n",
    "#     hf_dataset=hf_test_dataset,\n",
    "#     vocab=phoneme_vocab,\n",
    "#     mask_prob=0.15,\n",
    "#     max_length=512\n",
    "# )\n",
    "\n",
    "test_dataset = HuggingFacePhonemeDataset(hf_dataset_test, phoneme_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "802b655c-55d0-41ae-b4ff-5dec3b97674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test_dataset[2]\n",
    "\n",
    "input_ids = sample[\"input_ids\"].unsqueeze(0).to(model.device)\n",
    "labels = sample[\"labels\"].unsqueeze(0).to(model.device)\n",
    "prosody_ids = sample[\"prosody_ids\"].unsqueeze(0).to(model.device)\n",
    "prosody_labels = sample[\"prosody_labels\"].unsqueeze(0).to(model.device)\n",
    "attention_mask = sample[\"attention_mask\"].unsqueeze(0).to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bee1b25-da70-43ef-8a65-bc7e1b02870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phoneme Accuracy: 40.28%\n",
      "Prosody Accuracy: 8.33%\n",
      "Pos   5 | Phoneme: Pred=AH0 GT=IH1 → False\n",
      " | Prosody: Pred=153 GT=50 → False\n",
      "Pos   6 | Phoneme: Pred=N GT=S → False\n",
      " | Prosody: Pred=153 GT=133 → False\n",
      "Pos   9 | Phoneme: Pred=G GT=G → True\n",
      " | Prosody: Pred=7 GT=113 → False\n",
      "Pos  16 | Phoneme: Pred=AH0 GT=M → False\n",
      " | Prosody: Pred=7 GT=100 → False\n",
      "Pos  18 | Phoneme: Pred=ER0 GT=AA1 → False\n",
      " | Prosody: Pred=7 GT=71 → False\n",
      "Pos  26 | Phoneme: Pred=AY1 GT=IH1 → False\n",
      " | Prosody: Pred=153 GT=198 → False\n",
      "Pos  31 | Phoneme: Pred=R GT=R → True\n",
      " | Prosody: Pred=153 GT=44 → False\n",
      "Pos  44 | Phoneme: Pred=UW1 GT=UW1 → True\n",
      " | Prosody: Pred=7 GT=24 → False\n",
      "Pos  61 | Phoneme: Pred=DH GT=DH → True\n",
      " | Prosody: Pred=153 GT=47 → False\n",
      "Pos  63 | Phoneme: Pred=W GT=W → True\n",
      " | Prosody: Pred=7 GT=118 → False\n",
      "Pos  65 | Phoneme: Pred=Z GT=K → False\n",
      " | Prosody: Pred=7 GT=23 → False\n",
      "Pos  72 | Phoneme: Pred=AH0 GT=Y → False\n",
      " | Prosody: Pred=7 GT=184 → False\n",
      "Pos  73 | Phoneme: Pred=IH1 GT=EH1 → False\n",
      " | Prosody: Pred=153 GT=92 → False\n",
      "Pos  85 | Phoneme: Pred=L GT=N → False\n",
      " | Prosody: Pred=153 GT=71 → False\n",
      "Pos  97 | Phoneme: Pred=DH GT=Z → False\n",
      " | Prosody: Pred=153 GT=153 → True\n",
      "Pos  98 | Phoneme: Pred=AH0 GT=P → False\n",
      " | Prosody: Pred=153 GT=195 → False\n",
      "Pos 105 | Phoneme: Pred=R GT=R → True\n",
      " | Prosody: Pred=153 GT=46 → False\n",
      "Pos 114 | Phoneme: Pred=AE1 GT=AE1 → True\n",
      " | Prosody: Pred=71 GT=56 → False\n",
      "Pos 120 | Phoneme: Pred=AY1 GT=IH0 → False\n",
      " | Prosody: Pred=71 GT=118 → False\n",
      "Pos 134 | Phoneme: Pred=DH GT=Z → False\n",
      " | Prosody: Pred=7 GT=166 → False\n",
      "Pos 165 | Phoneme: Pred=L GT=L → True\n",
      " | Prosody: Pred=7 GT=71 → False\n",
      "Pos 171 | Phoneme: Pred=IH1 GT=IH1 → True\n",
      " | Prosody: Pred=156 GT=144 → False\n",
      "Pos 176 | Phoneme: Pred=AE1 GT=IH1 → False\n",
      " | Prosody: Pred=71 GT=8 → False\n",
      "Pos 217 | Phoneme: Pred=R GT=N → False\n",
      " | Prosody: Pred=153 GT=153 → True\n",
      "Pos 229 | Phoneme: Pred=N GT=N → True\n",
      " | Prosody: Pred=153 GT=118 → False\n",
      "Pos 235 | Phoneme: Pred=AH0 GT=AH0 → True\n",
      " | Prosody: Pred=153 GT=153 → True\n",
      "Pos 239 | Phoneme: Pred=D GT=D → True\n",
      " | Prosody: Pred=153 GT=12 → False\n",
      "Pos 241 | Phoneme: Pred=K GT=NG → False\n",
      " | Prosody: Pred=153 GT=166 → False\n",
      "Pos 246 | Phoneme: Pred=R GT=D → False\n",
      " | Prosody: Pred=153 GT=52 → False\n",
      "Pos 247 | Phoneme: Pred=S GT=Z → False\n",
      " | Prosody: Pred=153 GT=58 → False\n",
      "Pos 254 | Phoneme: Pred=IY0 GT=B → False\n",
      " | Prosody: Pred=7 GT=56 → False\n",
      "Pos 255 | Phoneme: Pred=S GT=AH1 → False\n",
      " | Prosody: Pred=153 GT=9 → False\n",
      "Pos 257 | Phoneme: Pred=W GT=HH → False\n",
      " | Prosody: Pred=7 GT=54 → False\n",
      "Pos 265 | Phoneme: Pred=AE1 GT=AE1 → True\n",
      " | Prosody: Pred=153 GT=181 → False\n",
      "Pos 271 | Phoneme: Pred=V GT=V → True\n",
      " | Prosody: Pred=7 GT=195 → False\n",
      "Pos 284 | Phoneme: Pred=IH0 GT=EH2 → False\n",
      " | Prosody: Pred=153 GT=112 → False\n",
      "Pos 285 | Phoneme: Pred=T GT=N → False\n",
      " | Prosody: Pred=7 GT=30 → False\n",
      "Pos 295 | Phoneme: Pred=L GT=L → True\n",
      " | Prosody: Pred=153 GT=174 → False\n",
      "Pos 317 | Phoneme: Pred=IH0 GT=AY1 → False\n",
      " | Prosody: Pred=153 GT=138 → False\n",
      "Pos 323 | Phoneme: Pred=D GT=R → False\n",
      " | Prosody: Pred=153 GT=113 → False\n",
      "Pos 346 | Phoneme: Pred=IY1 GT=ER1 → False\n",
      " | Prosody: Pred=153 GT=51 → False\n",
      "Pos 353 | Phoneme: Pred=IH0 GT=IH1 → False\n",
      " | Prosody: Pred=153 GT=71 → False\n",
      "Pos 365 | Phoneme: Pred=IH1 GT=AH0 → False\n",
      " | Prosody: Pred=153 GT=173 → False\n",
      "Pos 368 | Phoneme: Pred=T GT=M → False\n",
      " | Prosody: Pred=153 GT=161 → False\n",
      "Pos 383 | Phoneme: Pred=EY1 GT=EY1 → True\n",
      " | Prosody: Pred=156 GT=153 → False\n",
      "Pos 386 | Phoneme: Pred=N GT=N → True\n",
      " | Prosody: Pred=7 GT=118 → False\n",
      "Pos 388 | Phoneme: Pred=AH0 GT=AH0 → True\n",
      " | Prosody: Pred=7 GT=17 → False\n",
      "Pos 390 | Phoneme: Pred=AH0 GT=EH2 → False\n",
      " | Prosody: Pred=153 GT=141 → False\n",
      "Pos 400 | Phoneme: Pred=DH GT=DH → True\n",
      " | Prosody: Pred=7 GT=7 → True\n",
      "Pos 401 | Phoneme: Pred=AH0 GT=AH0 → True\n",
      " | Prosody: Pred=153 GT=193 → False\n",
      "Pos 402 | Phoneme: Pred=N GT=K → False\n",
      " | Prosody: Pred=153 GT=140 → False\n",
      "Pos 403 | Phoneme: Pred=AH0 GT=AA1 → False\n",
      " | Prosody: Pred=153 GT=151 → False\n",
      "Pos 411 | Phoneme: Pred=AH0 GT=AH0 → True\n",
      " | Prosody: Pred=153 GT=153 → True\n",
      "Pos 425 | Phoneme: Pred=N GT=Z → False\n",
      " | Prosody: Pred=173 GT=71 → False\n",
      "Pos 432 | Phoneme: Pred=SH GT=SH → True\n",
      " | Prosody: Pred=153 GT=95 → False\n",
      "Pos 437 | Phoneme: Pred=T GT=T → True\n",
      " | Prosody: Pred=153 GT=71 → False\n",
      "Pos 439 | Phoneme: Pred=IY1 GT=AH0 → False\n",
      " | Prosody: Pred=7 GT=7 → True\n",
      "Pos 440 | Phoneme: Pred=N GT=L → False\n",
      " | Prosody: Pred=153 GT=193 → False\n",
      "Pos 441 | Phoneme: Pred=T GT=B → False\n",
      " | Prosody: Pred=7 GT=74 → False\n",
      "Pos 455 | Phoneme: Pred=AH0 GT=AH0 → True\n",
      " | Prosody: Pred=7 GT=46 → False\n",
      "Pos 463 | Phoneme: Pred=IY1 GT=IY1 → True\n",
      " | Prosody: Pred=7 GT=133 → False\n",
      "Pos 466 | Phoneme: Pred=S GT=V → False\n",
      " | Prosody: Pred=153 GT=38 → False\n",
      "Pos 468 | Phoneme: Pred=AH0 GT=UW1 → False\n",
      " | Prosody: Pred=7 GT=52 → False\n",
      "Pos 469 | Phoneme: Pred=P GT=K → False\n",
      " | Prosody: Pred=153 GT=74 → False\n",
      "Pos 477 | Phoneme: Pred=N GT=N → True\n",
      " | Prosody: Pred=153 GT=30 → False\n",
      "Pos 478 | Phoneme: Pred=N GT=D → False\n",
      " | Prosody: Pred=153 GT=177 → False\n",
      "Pos 487 | Phoneme: Pred=N GT=NG → False\n",
      " | Prosody: Pred=7 GT=195 → False\n",
      "Pos 489 | Phoneme: Pred=AH0 GT=AH0 → True\n",
      " | Prosody: Pred=153 GT=158 → False\n",
      "Pos 495 | Phoneme: Pred=T GT=T → True\n",
      " | Prosody: Pred=46 GT=153 → False\n",
      "Pos 503 | Phoneme: Pred=IH1 GT=IH1 → True\n",
      " | Prosody: Pred=60 GT=66 → False\n",
      "Pos 505 | Phoneme: Pred=DH GT=AH0 → False\n",
      " | Prosody: Pred=7 GT=120 → False\n",
      "Pos 506 | Phoneme: Pred=B GT=N → False\n",
      " | Prosody: Pred=153 GT=151 → False\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, prosody_ids=prosody_ids, attention_mask=attention_mask)\n",
    "\n",
    "pred_phonemes = torch.argmax(outputs.logits, dim=-1)[0]         # [seq_len]\n",
    "pred_prosody = torch.argmax(outputs.prosody_logits, dim=-1)[0]  # [seq_len]\n",
    "\n",
    "# Evaluation\n",
    "id2phoneme = {v: k for k, v in phoneme_vocab.items()}\n",
    "mask_positions = (labels != -100).nonzero(as_tuple=True)[1].tolist()\n",
    "\n",
    "results = []\n",
    "correct_phoneme = 0\n",
    "correct_prosody = 0\n",
    "\n",
    "for i in mask_positions:\n",
    "    gt_ph_id = labels[0, i].item()\n",
    "    pred_ph_id = pred_phonemes[i].item()\n",
    "\n",
    "    gt_pr_id = prosody_labels[0, i].item()\n",
    "    pred_pr_id = pred_prosody[i].item()\n",
    "\n",
    "    phoneme_correct = gt_ph_id == pred_ph_id\n",
    "    prosody_correct = gt_pr_id == pred_pr_id\n",
    "\n",
    "    if phoneme_correct:\n",
    "        correct_phoneme += 1\n",
    "    if prosody_correct:\n",
    "        correct_prosody += 1\n",
    "\n",
    "    results.append({\n",
    "        \"position\": i,\n",
    "        \"phoneme_correct\": phoneme_correct,\n",
    "        \"phoneme_gt\": id2phoneme.get(gt_ph_id, \"UNK\"),\n",
    "        \"phoneme_pred\": id2phoneme.get(pred_ph_id, \"UNK\"),\n",
    "        \"phoneme_gt_id\": gt_ph_id,\n",
    "        \"phoneme_pred_id\": pred_ph_id,\n",
    "        \"prosody_correct\": prosody_correct,\n",
    "        \"prosody_gt_id\": gt_pr_id,\n",
    "        \"prosody_pred_id\": pred_pr_id,\n",
    "    })\n",
    "\n",
    "# Accuracy\n",
    "total = len(mask_positions)\n",
    "phoneme_accuracy = correct_phoneme / total if total > 0 else None\n",
    "prosody_accuracy = correct_prosody / total if total > 0 else None\n",
    "\n",
    "print(f\"\\nPhoneme Accuracy: {phoneme_accuracy:.2%}\" if phoneme_accuracy is not None else \"No masked phoneme positions.\")\n",
    "print(f\"Prosody Accuracy: {prosody_accuracy:.2%}\" if prosody_accuracy is not None else \"No masked prosody positions.\")\n",
    "\n",
    "for r in results:\n",
    "    print(f\"Pos {r['position']:>3} | Phoneme: Pred={r['phoneme_pred']} GT={r['phoneme_gt']} → {'True' if r['phoneme_correct'] else 'False'}\")\n",
    "    print(f\" | Prosody: Pred={r['prosody_pred_id']} GT={r['prosody_gt_id']} → {'True' if r['prosody_correct'] else 'False'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73c2387f-f227-442a-9a05-c7f3a6c74dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 100%|████████████████████| 1000/1000 [00:24<00:00, 40.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Evaluated 74471 masked positions over 1000 samples\n",
      "Phoneme Accuracy: 0.42%\n",
      "Prosody Accuracy: 11.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "total_phoneme_correct = 0\n",
    "total_prosody_correct = 0\n",
    "total_masked_positions = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for idx in tqdm(range(len(test_dataset)), desc=\"Evaluating samples\"):\n",
    "    sample = test_dataset[idx]\n",
    "\n",
    "    input_ids = sample[\"input_ids\"].unsqueeze(0).to(model.device)\n",
    "    labels = sample[\"prosody_labels\"].unsqueeze(0).to(model.device)\n",
    "    prosody_ids = sample[\"prosody_ids\"].unsqueeze(0).to(model.device)\n",
    "    prosody_labels = sample[\"prosody_labels\"].unsqueeze(0).to(model.device)\n",
    "    attention_mask = sample[\"attention_mask\"].unsqueeze(0).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, prosody_ids=prosody_ids, attention_mask=attention_mask)\n",
    "\n",
    "    pred_phonemes = torch.argmax(outputs.logits, dim=-1)[0]\n",
    "    pred_prosody = torch.argmax(outputs.prosody_logits, dim=-1)[0]\n",
    "    mask_positions = (labels != -100).nonzero(as_tuple=True)[1].tolist()\n",
    "\n",
    "    for i in mask_positions:\n",
    "        gt_ph_id = labels[0, i].item()\n",
    "        pred_ph_id = pred_phonemes[i].item()\n",
    "        gt_pr_id = prosody_labels[0, i].item()\n",
    "        pred_pr_id = pred_prosody[i].item()\n",
    "\n",
    "        total_masked_positions += 1\n",
    "        if gt_ph_id == pred_ph_id:\n",
    "            total_phoneme_correct += 1\n",
    "        if gt_pr_id == pred_pr_id:\n",
    "            total_prosody_correct += 1\n",
    "\n",
    "# === Final accuracy calculation ===\n",
    "if total_masked_positions > 0:\n",
    "    avg_phoneme_acc = total_phoneme_correct / total_masked_positions\n",
    "    avg_prosody_acc = total_prosody_correct / total_masked_positions\n",
    "else:\n",
    "    avg_phoneme_acc = avg_prosody_acc = None\n",
    "\n",
    "print(f\"\\n✅ Evaluated {total_masked_positions} masked positions over {len(test_dataset)} samples\")\n",
    "print(f\"Phoneme Accuracy: {avg_phoneme_acc:.2%}\" if avg_phoneme_acc is not None else \"No masked phoneme positions.\")\n",
    "print(f\"Prosody Accuracy: {avg_prosody_acc:.2%}\" if avg_prosody_acc is not None else \"No masked prosody positions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d970cb0-fa27-49d5-a355-bd9f058aa573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539bb2fc-acd8-41bc-8a56-3e20901d85af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9462e767-3c73-4aab-a800-acf557fd7784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b10ae80-a852-4898-bf68-78cb5cbe4bba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
