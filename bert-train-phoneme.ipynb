{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca76531-4caf-42f6-8f52-c81dd802aaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 17:42:14.664769: I tensorflow/core/platform/cpu_feature_guard.cc:181] Beginning TensorFlow 2.15, this package will be updated to install stock TensorFlow 2.15 alongside Intel's TensorFlow CPU extension plugin, which provides all the optimizations available in the package and more. If a compatible version of stock TensorFlow is present, only the extension will get installed. No changes to code or installation setup is needed as a result of this change.\n",
      "More information on Intel's optimizations for TensorFlow, delivered as TensorFlow extension plugin can be viewed at https://github.com/intel/intel-extension-for-tensorflow.\n",
      "2025-03-31 17:42:14.664815: I tensorflow/core/platform/cpu_feature_guard.cc:192] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from transformers import AdamW\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import *\n",
    "from tokenizers import *\n",
    "\n",
    "from bertPhoneme import BertEmbeddingsV2, BertModelV2, BertForMaskedLMV2, BertConfigV2, MaskedLMWithProsodyOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c403dc3-7c84-4c7c-b50c-fd1db50a124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your phoneme-to-ID mapping\n",
    "phoneme_vocab = { \"AA\": 0, \"AE\": 1, \"AH\": 2, \"AO\": 3, \"AW\": 4, \"AY\": 5, \n",
    "                  \"B\": 6, \"CH\": 7, \"D\": 8, \"DH\": 9, \"EH\": 10, \"ER\": 11, \"EY\": 12, \n",
    "                  \"F\": 13, \"G\": 14, \"H\": 15, \"IH\": 16, \"IY\": 17, \"JH\": 18, \"K\": 19, \n",
    "                  \"L\": 20, \"M\": 21, \"N\": 22, \"NG\": 23, \"OW\": 24, \"OY\": 25, \"P\": 26, \n",
    "                  \"R\": 27, \"S\": 28, \"SH\": 29, \"T\": 30, \"TH\": 31, \"UH\": 32, \"UW\": 33, \n",
    "                  \"V\": 34, \"W\": 35, \"Y\": 36, \"Z\": 37, \"ZH\": 38, \"PAUSE\": 39, \"SIL\": 40 }\n",
    "\n",
    "phoneme_vocab_size = len(phoneme_vocab)  # e.g., 41 phonemes\n",
    "mask_token_id = phoneme_vocab[\"SIL\"]  # Use SIL as [MASK]\n",
    "\n",
    "# Example dataset\n",
    "dataset = [\n",
    "    ([\"DH\", \"AH\", \"S\", \"IH\", \"Z\", \"AH\", \"T\", \"EH\", \"S\", \"T\"], [0, 1, 1, 2, 2, 1, 1, 0, 1, 1]),\n",
    "    ([\"B\", \"AH\", \"T\", \"ER\", \"IH\", \"S\", \"TH\", \"AA\", \"N\"], [2, 2, 1, 1, 1, 2, 0, 1, 1]),\n",
    "    ([\"DH\", \"AH\", \"ER\", \"IH\", \"Z\", \"AH\", \"T\", \"EH\", \"S\", \"T\"], [0, 1, 0, 2, 2, 1, 1, 0, 1, 1]),\n",
    "    ([\"S\", \"P\", \"IY\", \"CH\", \"IH\", \"Z\", \"K\", \"L\", \"EH\", \"R\"], [1, 1, 2, 2, 1, 0, 0, 1, 1, 1]),\n",
    "    ([\"TH\", \"AE\", \"V\", \"Y\", \"UW\", \"S\", \"T\", \"IH\", \"CH\"], [0, 0, 1, 1, 2, 2, 1, 1, 1]),\n",
    "    ([\"K\", \"AO\", \"L\", \"D\", \"S\", \"T\", \"AA\", \"R\", \"T\", \"IH\", \"NG\"], [1, 1, 2, 2, 0, 1, 1, 2, 1, 1, 1]),\n",
    "    ([\"W\", \"EH\", \"N\", \"D\", \"IH\", \"Z\", \"DH\", \"AH\", \"K\", \"EY\", \"S\"], [2, 1, 1, 2, 1, 0, 0, 1, 1, 1, 1]),\n",
    "    ([\"N\", \"OW\", \"Y\", \"UW\", \"K\", \"AE\", \"N\", \"S\", \"T\", \"AA\", \"P\", \"M\", \"IY\"], [0, 1, 1, 2, 2, 1, 0, 0, 1, 1, 2, 2, 1]),\n",
    "    ([\"IH\", \"T\", \"W\", \"AA\", \"Z\", \"AH\", \"K\", \"L\", \"EH\", \"R\", \"D\", \"EY\"], [1, 1, 2, 2, 1, 0, 0, 1, 1, 2, 2, 1]),\n",
    "    ([\"TH\", \"AW\", \"K\", \"AE\", \"N\", \"W\", \"IY\", \"G\", \"IH\", \"V\", \"DH\", \"AH\", \"CH\", \"AE\", \"N\", \"S\"], [0, 0, 1, 1, 2, 2, 1, 0, 1, 1, 2, 2, 1, 0, 1, 1]),\n",
    "    ([\"AY\", \"W\", \"AA\", \"N\", \"T\", \"T\", \"UW\", \"G\", \"OW\"], [1, 1, 2, 2, 0, 0, 1, 1, 1]),\n",
    "    ([\"SH\", \"IY\", \"S\", \"EH\", \"D\", \"DH\", \"AH\", \"T\", \"UW\", \"TH\"], [1, 2, 2, 1, 1, 0, 0, 2, 2, 1]),\n",
    "    ([\"Y\", \"UW\", \"K\", \"AE\", \"N\", \"N\", \"AA\", \"T\", \"B\", \"IY\", \"S\", \"IH\", \"R\", \"IY\", \"UH\", \"S\"], [1, 1, 2, 2, 2, 1, 0, 0, 0, 1, 1, 2, 1, 1, 2, 2]),\n",
    "    ([\"K\", \"AE\", \"N\", \"Y\", \"UW\", \"R\", \"IY\", \"P\", \"IY\", \"T\", \"DH\", \"AE\", \"T\"], [1, 1, 2, 2, 2, 1, 1, 0, 0, 1, 0, 1, 1]),\n",
    "    ([\"B\", \"IH\", \"G\", \"CH\", \"EY\", \"N\", \"JH\", \"IH\", \"Z\", \"K\", \"AH\", \"M\", \"IH\", \"NG\"], [0, 1, 1, 2, 2, 2, 1, 1, 0, 0, 0, 1, 1, 1]),\n",
    "    ([\"DH\", \"AH\", \"B\", \"EH\", \"S\", \"T\", \"W\", \"EY\", \"T\", \"T\", \"UW\", \"D\", \"UW\", \"IH\", \"T\"], [0, 1, 1, 2, 2, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1]),\n",
    "    ([\"AY\", \"K\", \"AE\", \"N\", \"TH\", \"EH\", \"L\", \"P\", \"Y\", \"UW\"], [1, 2, 2, 1, 1, 0, 0, 1, 1, 2]),\n",
    "    ([\"IH\", \"IY\", \"D\", \"IH\", \"D\", \"N\", \"AA\", \"T\", \"K\", \"AA\", \"L\"], [0, 1, 1, 2, 2, 2, 1, 1, 0, 0, 1]),\n",
    "    ([\"IH\", \"F\", \"Y\", \"UW\", \"K\", \"AE\", \"N\", \"R\", \"IY\", \"D\", \"DH\", \"IH\", \"S\"], [1, 1, 2, 2, 2, 1, 0, 0, 1, 1, 2, 2, 1]),\n",
    "    ([\"AY\", \"IH\", \"OW\", \"P\", \"Y\", \"UW\", \"L\", \"AY\", \"K\", \"IH\", \"T\"], [1, 1, 2, 2, 1, 0, 0, 1, 1, 2, 2])\n",
    "]\n",
    "\n",
    "\n",
    "class PhonemeProsodyDataset(Dataset):\n",
    "    def __init__(self, data, vocab, mask_prob=0.2, max_length=20):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.mask_prob = mask_prob\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        phonemes, prosody_ids = self.data[idx]\n",
    "\n",
    "        # Convert phonemes to IDs\n",
    "        input_ids = [self.vocab[p] for p in phonemes]\n",
    "        prosody_ids = prosody_ids[:self.max_length]\n",
    "\n",
    "        # Apply MLM (random masking)\n",
    "        labels = input_ids.copy()\n",
    "        for i in range(len(input_ids)):\n",
    "            if random.random() < self.mask_prob:\n",
    "                labels[i] = input_ids[i]  # Keep the original label\n",
    "                input_ids[i] = mask_token_id  # Replace with mask token\n",
    "\n",
    "        # Padding\n",
    "        pad_length = self.max_length - len(input_ids)\n",
    "        input_ids.extend([0] * pad_length)\n",
    "        labels.extend([-100] * pad_length)  # -100 for ignored loss computation\n",
    "        prosody_ids.extend([0] * pad_length)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "            \"prosody_ids\": torch.tensor(prosody_ids, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = PhonemeProsodyDataset(dataset, phoneme_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a01d475a-223d-4671-b5f7-924201779243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 9, 40, 28, 16, 37, 40, 30, 10, 28, 30,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0]),\n",
       " 'labels': tensor([   9,    2,   28,   16,   37,    2,   30,   10,   28,   30, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100]),\n",
       " 'prosody_ids': tensor([0, 1, 1, 2, 2, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4261f08a-8c9d-4d70-b67c-7608045fe1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1c18a2e-ce10-4a97-8cbf-e757a28ae164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[40, 40, 40, 10,  8, 40,  2, 30, 33, 31,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0],\n",
      "        [31,  1, 34, 36, 40, 28, 40, 16,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0]]), 'labels': tensor([[  29,   17,   28,   10,    8,    9,    2,   30,   33,   31, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100],\n",
      "        [  31,    1,   34,   36,   33,   28,   30,   16,    7, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100]]), 'prosody_ids': tensor([[1, 2, 2, 1, 1, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 1, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fbbbaf0-b9da-4649-be17-47904851752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 40 # len(phoneme_vocab.keys())\n",
    "max_length = 20\n",
    "\n",
    "model_config = BertConfigV2(\n",
    "    vocab_size=vocab_size,\n",
    "    hidden_size=128,\n",
    "    num_hidden_layers=2,\n",
    "    num_attention_heads=2,\n",
    "    intermediate_size=512,\n",
    "    max_position_embeddings=max_length,\n",
    "    prosody_cluster_size=4,\n",
    "    pad_token_id=3\n",
    ")\n",
    "\n",
    "model = BertForMaskedLMV2(config=model_config)\n",
    "\n",
    "# BERT-Base\t768\t12\t12\t3072\n",
    "# BERT-Small 512\t4\t8\t2048\n",
    "# BERT-Mini\t256\t4\t4\t1024\n",
    "# BERT-Tiny\t128\t2\t2\t512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f0028c-cbbb-418d-a55a-c783e30472b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLMV2(\n",
       "  (bert): BertModelV2(\n",
       "    (embeddings): BertEmbeddingsV2(\n",
       "      (word_embeddings): Embedding(40, 128, padding_idx=3)\n",
       "      (position_embeddings): Embedding(20, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (prosody_embeddings): Embedding(4, 128, padding_idx=3)\n",
       "      (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=128, out_features=40, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (prosody_head): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53cef04b-4a26-46aa-a4be-344ff7a9a255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     14\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     17\u001b[0m         input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m         labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Define loss functions\n",
    "mlm_loss_fn = nn.CrossEntropyLoss(ignore_index=-100)  # MLM Loss\n",
    "prosody_loss_fn = nn.CrossEntropyLoss()  # Prosody Classification Loss\n",
    "\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        prosody_ids = batch[\"prosody_ids\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, prosody_ids=prosody_ids)\n",
    "\n",
    "        # Compute losses\n",
    "        mlm_loss = mlm_loss_fn(outputs.logits.view(-1, phoneme_vocab_size), labels.view(-1))\n",
    "        prosody_loss = prosody_loss_fn(outputs.prosody_logits.view(-1, model.config.prosody_cluster_size), prosody_ids.view(-1))\n",
    "\n",
    "        # Combine losses\n",
    "        total_batch_loss = mlm_loss + prosody_loss\n",
    "        total_batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += total_batch_loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "481f2209-7014-4f9f-b9f4-5ff13ba6cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = [\n",
    "    ([\"DH\", \"S\", \"IH\", \"Z\", \"AH\", \"T\", \"EH\", \"S\", \"T\"], [0, 1, 2, 2, 1, 1, 0, 1, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bf7c283-8bef-4a00-8ead-5ac2467f74c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 9, 28, 16, 40,  2, 30, 10, 40, 30,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0]),\n",
       " 'labels': tensor([   9,   28,   16,   37,    2,   30,   10,   28,   30, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100]),\n",
       " 'prosody_ids': tensor([0, 1, 2, 2, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = PhonemeProsodyDataset(test_dataset, phoneme_vocab)\n",
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9dcd16b5-46f4-4a73-a6e5-460c0bc641d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "input_ids = test_dataset[0][\"input_ids\"].unsqueeze(0).to(device)     # shape: [1, seq_len]\n",
    "labels = test_dataset[0][\"labels\"].unsqueeze(0).to(device)           # shape: [1, seq_len]\n",
    "prosody_ids = test_dataset[0][\"prosody_ids\"].unsqueeze(0).to(device) # shape: [1, seq_len]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, prosody_ids=prosody_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c65b71b-12b7-4dc6-a2a0-59353a8e12b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predictions for masked tokens (SIL):\n",
      "\n",
      "Token 2 (Masked Position):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    AH: 0.4596\n",
      "    AE: 0.0711\n",
      "    OW: 0.0620\n",
      "    AO: 0.0358\n",
      "    NG: 0.0338\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 1: 0.9979\n",
      "    Cluster 0: 0.0017\n",
      "    Cluster 2: 0.0005\n",
      "----------------------------------------\n",
      "Token 7 (Masked Position):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    EH: 0.2366\n",
      "    W: 0.2217\n",
      "    IH: 0.0439\n",
      "    B: 0.0438\n",
      "    EY: 0.0413\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.9802\n",
      "    Cluster 2: 0.0134\n",
      "    Cluster 1: 0.0065\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Assume you have access to phoneme_vocab and its inverse mapping\n",
    "id2phoneme = {v: k for k, v in phoneme_vocab.items()}\n",
    "phoneme_logits = outputs.logits[0]  # shape: [seq_len, vocab_size]\n",
    "prosody_logits = outputs.prosody_logits[0]  # shape: [seq_len, prosody_cluster_size]\n",
    "\n",
    "print(\"Top 5 predictions for masked tokens (SIL):\\n\")\n",
    "\n",
    "for i in range(input_ids.shape[1]):  # loop over tokens in sequence\n",
    "    if input_ids[0, i].item() != phoneme_vocab[\"SIL\"]:\n",
    "        continue  # Only predict for masked tokens\n",
    "\n",
    "    print(f\"Token {i + 1} (Masked Position):\")\n",
    "\n",
    "    # ==== Phoneme Prediction ====\n",
    "    phoneme_probs = torch.softmax(phoneme_logits[i], dim=-1)\n",
    "    top5_phoneme = torch.topk(phoneme_probs, 5)\n",
    "    print(\"  Top 5 Phoneme Predictions:\")\n",
    "    for j in range(5):\n",
    "        pid = top5_phoneme.indices[j].item()\n",
    "        prob = top5_phoneme.values[j].item()\n",
    "        print(f\"    {id2phoneme[pid]}: {prob:.4f}\")\n",
    "\n",
    "    # ==== Prosody Prediction ====\n",
    "    prosody_probs = torch.softmax(prosody_logits[i], dim=-1)\n",
    "    top5_prosody = torch.topk(prosody_probs, min(5, prosody_probs.size(-1)))\n",
    "    print(\"  Top Prosody Predictions:\")\n",
    "    for j in range(top5_prosody.indices.size(0)):\n",
    "        pid = top5_prosody.indices[j].item()\n",
    "        prob = top5_prosody.values[j].item()\n",
    "        print(f\"    Cluster {pid}: {prob:.4f}\")\n",
    "    \n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f1f90-8e65-40ac-87bd-c86d9f1ee4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
