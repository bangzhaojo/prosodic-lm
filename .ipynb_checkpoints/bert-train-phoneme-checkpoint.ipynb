{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ca76531-4caf-42f6-8f52-c81dd802aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from transformers import AdamW\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import *\n",
    "from tokenizers import *\n",
    "\n",
    "from bertPhoneme import BertEmbeddingsV2, BertModelV2, BertForMaskedLMV2, BertConfigV2, MaskedLMWithProsodyOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c403dc3-7c84-4c7c-b50c-fd1db50a124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your phoneme-to-ID mapping\n",
    "phoneme_vocab = { \"AA\": 0, \"AE\": 1, \"AH\": 2, \"AO\": 3, \"AW\": 4, \"AY\": 5, \n",
    "                  \"B\": 6, \"CH\": 7, \"D\": 8, \"DH\": 9, \"EH\": 10, \"ER\": 11, \"EY\": 12, \n",
    "                  \"F\": 13, \"G\": 14, \"H\": 15, \"IH\": 16, \"IY\": 17, \"JH\": 18, \"K\": 19, \n",
    "                  \"L\": 20, \"M\": 21, \"N\": 22, \"NG\": 23, \"OW\": 24, \"OY\": 25, \"P\": 26, \n",
    "                  \"R\": 27, \"S\": 28, \"SH\": 29, \"T\": 30, \"TH\": 31, \"UH\": 32, \"UW\": 33, \n",
    "                  \"V\": 34, \"W\": 35, \"Y\": 36, \"Z\": 37, \"ZH\": 38, \"PAUSE\": 39, \"SIL\": 40 }\n",
    "\n",
    "phoneme_vocab_size = len(phoneme_vocab)  # e.g., 41 phonemes\n",
    "mask_token_id = phoneme_vocab[\"SIL\"]  # Use SIL as [MASK]\n",
    "\n",
    "# Example dataset\n",
    "dataset = [\n",
    "    ([\"DH\", \"AH\", \"S\", \"IH\", \"Z\", \"AH\", \"T\", \"EH\", \"S\", \"T\"], [0, 1, 1, 2, 2, 1, 1, 0, 1, 1]),\n",
    "    ([\"B\", \"AH\", \"T\", \"ER\", \"IH\", \"S\", \"TH\", \"AA\", \"N\"], [2, 2, 1, 1, 1, 2, 0, 1, 1]),\n",
    "    ([\"DH\", \"AH\", \"ER\", \"IH\", \"Z\", \"AH\", \"T\", \"EH\", \"S\", \"T\"], [0, 1, 0, 2, 2, 1, 1, 0, 1, 1]),\n",
    "    ([\"S\", \"P\", \"IY\", \"CH\", \"IH\", \"Z\", \"K\", \"L\", \"EH\", \"R\"], [1, 1, 2, 2, 1, 0, 0, 1, 1, 1]),\n",
    "    ([\"TH\", \"AE\", \"V\", \"Y\", \"UW\", \"S\", \"T\", \"IH\", \"CH\"], [0, 0, 1, 1, 2, 2, 1, 1, 1]),\n",
    "    ([\"K\", \"AO\", \"L\", \"D\", \"S\", \"T\", \"AA\", \"R\", \"T\", \"IH\", \"NG\"], [1, 1, 2, 2, 0, 1, 1, 2, 1, 1, 1]),\n",
    "    ([\"W\", \"EH\", \"N\", \"D\", \"IH\", \"Z\", \"DH\", \"AH\", \"K\", \"EY\", \"S\"], [2, 1, 1, 2, 1, 0, 0, 1, 1, 1, 1]),\n",
    "    ([\"N\", \"OW\", \"Y\", \"UW\", \"K\", \"AE\", \"N\", \"S\", \"T\", \"AA\", \"P\", \"M\", \"IY\"], [0, 1, 1, 2, 2, 1, 0, 0, 1, 1, 2, 2, 1]),\n",
    "    ([\"IH\", \"T\", \"W\", \"AA\", \"Z\", \"AH\", \"K\", \"L\", \"EH\", \"R\", \"D\", \"EY\"], [1, 1, 2, 2, 1, 0, 0, 1, 1, 2, 2, 1]),\n",
    "    ([\"TH\", \"AW\", \"K\", \"AE\", \"N\", \"W\", \"IY\", \"G\", \"IH\", \"V\", \"DH\", \"AH\", \"CH\", \"AE\", \"N\", \"S\"], [0, 0, 1, 1, 2, 2, 1, 0, 1, 1, 2, 2, 1, 0, 1, 1]),\n",
    "    ([\"AY\", \"W\", \"AA\", \"N\", \"T\", \"T\", \"UW\", \"G\", \"OW\"], [1, 1, 2, 2, 0, 0, 1, 1, 1]),\n",
    "    ([\"SH\", \"IY\", \"S\", \"EH\", \"D\", \"DH\", \"AH\", \"T\", \"UW\", \"TH\"], [1, 2, 2, 1, 1, 0, 0, 2, 2, 1]),\n",
    "    ([\"Y\", \"UW\", \"K\", \"AE\", \"N\", \"N\", \"AA\", \"T\", \"B\", \"IY\", \"S\", \"IH\", \"R\", \"IY\", \"UH\", \"S\"], [1, 1, 2, 2, 2, 1, 0, 0, 0, 1, 1, 2, 1, 1, 2, 2]),\n",
    "    ([\"K\", \"AE\", \"N\", \"Y\", \"UW\", \"R\", \"IY\", \"P\", \"IY\", \"T\", \"DH\", \"AE\", \"T\"], [1, 1, 2, 2, 2, 1, 1, 0, 0, 1, 0, 1, 1]),\n",
    "    ([\"B\", \"IH\", \"G\", \"CH\", \"EY\", \"N\", \"JH\", \"IH\", \"Z\", \"K\", \"AH\", \"M\", \"IH\", \"NG\"], [0, 1, 1, 2, 2, 2, 1, 1, 0, 0, 0, 1, 1, 1]),\n",
    "    ([\"DH\", \"AH\", \"B\", \"EH\", \"S\", \"T\", \"W\", \"EY\", \"T\", \"T\", \"UW\", \"D\", \"UW\", \"IH\", \"T\"], [0, 1, 1, 2, 2, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1]),\n",
    "    ([\"AY\", \"K\", \"AE\", \"N\", \"TH\", \"EH\", \"L\", \"P\", \"Y\", \"UW\"], [1, 2, 2, 1, 1, 0, 0, 1, 1, 2]),\n",
    "    ([\"IH\", \"IY\", \"D\", \"IH\", \"D\", \"N\", \"AA\", \"T\", \"K\", \"AA\", \"L\"], [0, 1, 1, 2, 2, 2, 1, 1, 0, 0, 1]),\n",
    "    ([\"IH\", \"F\", \"Y\", \"UW\", \"K\", \"AE\", \"N\", \"R\", \"IY\", \"D\", \"DH\", \"IH\", \"S\"], [1, 1, 2, 2, 2, 1, 0, 0, 1, 1, 2, 2, 1]),\n",
    "    ([\"AY\", \"IH\", \"OW\", \"P\", \"Y\", \"UW\", \"L\", \"AY\", \"K\", \"IH\", \"T\"], [1, 1, 2, 2, 1, 0, 0, 1, 1, 2, 2])\n",
    "]\n",
    "\n",
    "\n",
    "class PhonemeProsodyDataset(Dataset):\n",
    "    def __init__(self, data, vocab, mask_prob=0.25, max_length=20):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.mask_prob = mask_prob\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        phonemes, prosody_ids = self.data[idx]\n",
    "\n",
    "        # Convert phonemes to IDs\n",
    "        input_ids = [self.vocab[p] for p in phonemes]\n",
    "        prosody_ids = prosody_ids[:self.max_length]\n",
    "\n",
    "        # Apply MLM (random masking)\n",
    "        labels = input_ids.copy()\n",
    "        for i in range(len(input_ids)):\n",
    "            if random.random() < self.mask_prob:\n",
    "                labels[i] = input_ids[i]  # Keep the original label\n",
    "                input_ids[i] = mask_token_id  # Replace with mask token\n",
    "\n",
    "        # Padding\n",
    "        pad_length = self.max_length - len(input_ids)\n",
    "        input_ids.extend([0] * pad_length)\n",
    "        labels.extend([-100] * pad_length)  # -100 for ignored loss computation\n",
    "        prosody_ids.extend([0] * pad_length)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "            \"prosody_ids\": torch.tensor(prosody_ids, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = PhonemeProsodyDataset(dataset, phoneme_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d475a-223d-4671-b5f7-924201779243",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261f08a-8c9d-4d70-b67c-7608045fe1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c18a2e-ce10-4a97-8cbf-e757a28ae164",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbbaf0-b9da-4649-be17-47904851752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(phoneme_vocab.keys())\n",
    "max_length = 20\n",
    "\n",
    "\n",
    "model_config = BertConfigV2(\n",
    "    vocab_size=vocab_size,\n",
    "    hidden_size=128,\n",
    "    num_hidden_layers=2,\n",
    "    num_attention_heads=2,\n",
    "    intermediate_size=512,\n",
    "    max_position_embeddings=max_length,\n",
    "    prosody_cluster_size=3\n",
    ")\n",
    "\n",
    "model = BertForMaskedLMV2(config=model_config)\n",
    "\n",
    "# BERT-Base\t768\t12\t12\t3072\n",
    "# BERT-Small 512\t4\t8\t2048\n",
    "# BERT-Mini\t256\t4\t4\t1024\n",
    "# BERT-Tiny\t128\t2\t2\t512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0028c-cbbb-418d-a55a-c783e30472b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "53cef04b-4a26-46aa-a4be-344ff7a9a255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 4.800920820236206\n",
      "Epoch 2: Loss = 4.656748056411743\n",
      "Epoch 3: Loss = 4.541573143005371\n",
      "Epoch 4: Loss = 4.443735122680664\n",
      "Epoch 5: Loss = 4.368757009506226\n",
      "Epoch 6: Loss = 4.298747396469116\n",
      "Epoch 7: Loss = 4.222767400741577\n",
      "Epoch 8: Loss = 4.152597379684448\n",
      "Epoch 9: Loss = 4.097935938835144\n",
      "Epoch 10: Loss = 4.034598350524902\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "# Define loss functions\n",
    "mlm_loss_fn = nn.CrossEntropyLoss(ignore_index=-100)  # MLM Loss\n",
    "prosody_loss_fn = nn.CrossEntropyLoss()  # Prosody Classification Loss\n",
    "\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        prosody_ids = batch[\"prosody_ids\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, prosody_ids=prosody_ids)\n",
    "\n",
    "        # Compute losses\n",
    "        mlm_loss = mlm_loss_fn(outputs.logits.view(-1, phoneme_vocab_size), labels.view(-1))\n",
    "        prosody_loss = prosody_loss_fn(outputs.prosody_logits.view(-1, model.config.prosody_cluster_size), prosody_ids.view(-1))\n",
    "\n",
    "        # Combine losses\n",
    "        total_batch_loss = mlm_loss + prosody_loss\n",
    "        total_batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += total_batch_loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "481f2209-7014-4f9f-b9f4-5ff13ba6cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = [\n",
    "    ([\"DH\", \"S\", \"IH\", \"SIL\", \"AH\", \"T\", \"EH\", \"S\", \"T\"], [0, 1, 2, 2, 1, 1, 0, 1, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5bf7c283-8bef-4a00-8ead-5ac2467f74c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 9, 28, 16, 37,  2, 40, 10, 28, 30,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0]),\n",
       " 'labels': tensor([   9,   28,   16,   37,    2,   30,   10,   28,   30, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100]),\n",
       " 'prosody_ids': tensor([0, 1, 2, 2, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = PhonemeProsodyDataset(test_dataset, phoneme_vocab)\n",
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9dcd16b5-46f4-4a73-a6e5-460c0bc641d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "input_ids = test_dataset[0][\"input_ids\"].unsqueeze(0).to(device)     # shape: [1, seq_len]\n",
    "labels = test_dataset[0][\"labels\"].unsqueeze(0).to(device)           # shape: [1, seq_len]\n",
    "prosody_ids = test_dataset[0][\"prosody_ids\"].unsqueeze(0).to(device) # shape: [1, seq_len]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, prosody_ids=prosody_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9c65b71b-12b7-4dc6-a2a0-59353a8e12b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predictions per token:\n",
      "\n",
      "Token 1 (Input Phoneme: DH):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0503\n",
      "    S: 0.0421\n",
      "    IH: 0.0413\n",
      "    AE: 0.0385\n",
      "    IY: 0.0364\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.4575\n",
      "    Cluster 1: 0.3541\n",
      "    Cluster 2: 0.1884\n",
      "----------------------------------------\n",
      "Token 2 (Input Phoneme: S):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    S: 0.0527\n",
      "    T: 0.0488\n",
      "    N: 0.0478\n",
      "    AH: 0.0431\n",
      "    IY: 0.0377\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 1: 0.4344\n",
      "    Cluster 0: 0.3952\n",
      "    Cluster 2: 0.1704\n",
      "----------------------------------------\n",
      "Token 3 (Input Phoneme: SIL):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0445\n",
      "    S: 0.0441\n",
      "    K: 0.0408\n",
      "    UW: 0.0389\n",
      "    IH: 0.0382\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.5339\n",
      "    Cluster 1: 0.2542\n",
      "    Cluster 2: 0.2119\n",
      "----------------------------------------\n",
      "Token 4 (Input Phoneme: Z):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    IH: 0.0521\n",
      "    N: 0.0435\n",
      "    UW: 0.0421\n",
      "    K: 0.0375\n",
      "    T: 0.0361\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 1: 0.4500\n",
      "    Cluster 2: 0.3307\n",
      "    Cluster 0: 0.2193\n",
      "----------------------------------------\n",
      "Token 5 (Input Phoneme: AH):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0551\n",
      "    IH: 0.0441\n",
      "    S: 0.0430\n",
      "    UW: 0.0380\n",
      "    AE: 0.0375\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 1: 0.4626\n",
      "    Cluster 0: 0.2778\n",
      "    Cluster 2: 0.2596\n",
      "----------------------------------------\n",
      "Token 6 (Input Phoneme: T):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0654\n",
      "    S: 0.0557\n",
      "    N: 0.0398\n",
      "    Z: 0.0354\n",
      "    IY: 0.0350\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 1: 0.4408\n",
      "    Cluster 0: 0.4269\n",
      "    Cluster 2: 0.1323\n",
      "----------------------------------------\n",
      "Token 7 (Input Phoneme: EH):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0556\n",
      "    IH: 0.0394\n",
      "    IY: 0.0390\n",
      "    K: 0.0367\n",
      "    AE: 0.0347\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.5110\n",
      "    Cluster 1: 0.3119\n",
      "    Cluster 2: 0.1771\n",
      "----------------------------------------\n",
      "Token 8 (Input Phoneme: S):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0594\n",
      "    IH: 0.0519\n",
      "    UW: 0.0430\n",
      "    S: 0.0411\n",
      "    N: 0.0352\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 1: 0.4190\n",
      "    Cluster 0: 0.4169\n",
      "    Cluster 2: 0.1641\n",
      "----------------------------------------\n",
      "Token 9 (Input Phoneme: T):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0643\n",
      "    S: 0.0430\n",
      "    IH: 0.0414\n",
      "    N: 0.0374\n",
      "    UW: 0.0359\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 1: 0.4807\n",
      "    Cluster 0: 0.3684\n",
      "    Cluster 2: 0.1509\n",
      "----------------------------------------\n",
      "Token 10 (Input Phoneme: AA):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0517\n",
      "    IY: 0.0485\n",
      "    K: 0.0442\n",
      "    N: 0.0402\n",
      "    S: 0.0396\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.6219\n",
      "    Cluster 1: 0.2341\n",
      "    Cluster 2: 0.1441\n",
      "----------------------------------------\n",
      "Token 11 (Input Phoneme: AA):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    S: 0.0593\n",
      "    T: 0.0519\n",
      "    IY: 0.0469\n",
      "    N: 0.0469\n",
      "    K: 0.0420\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.7087\n",
      "    Cluster 1: 0.1776\n",
      "    Cluster 2: 0.1137\n",
      "----------------------------------------\n",
      "Token 12 (Input Phoneme: AA):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0540\n",
      "    IY: 0.0474\n",
      "    S: 0.0437\n",
      "    N: 0.0411\n",
      "    IH: 0.0393\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.7267\n",
      "    Cluster 1: 0.1527\n",
      "    Cluster 2: 0.1206\n",
      "----------------------------------------\n",
      "Token 13 (Input Phoneme: AA):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0607\n",
      "    IY: 0.0519\n",
      "    S: 0.0419\n",
      "    N: 0.0391\n",
      "    AH: 0.0339\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.7542\n",
      "    Cluster 1: 0.1511\n",
      "    Cluster 2: 0.0948\n",
      "----------------------------------------\n",
      "Token 14 (Input Phoneme: AA):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0557\n",
      "    IY: 0.0442\n",
      "    S: 0.0434\n",
      "    N: 0.0433\n",
      "    K: 0.0377\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.7420\n",
      "    Cluster 1: 0.1609\n",
      "    Cluster 2: 0.0971\n",
      "----------------------------------------\n",
      "Token 15 (Input Phoneme: AA):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0604\n",
      "    S: 0.0536\n",
      "    N: 0.0482\n",
      "    IY: 0.0462\n",
      "    K: 0.0360\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.7293\n",
      "    Cluster 1: 0.1697\n",
      "    Cluster 2: 0.1009\n",
      "----------------------------------------\n",
      "Token 16 (Input Phoneme: AA):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0612\n",
      "    IY: 0.0483\n",
      "    S: 0.0432\n",
      "    K: 0.0377\n",
      "    Z: 0.0369\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.7580\n",
      "    Cluster 1: 0.1409\n",
      "    Cluster 2: 0.1012\n",
      "----------------------------------------\n",
      "Token 17 (Input Phoneme: AA):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0497\n",
      "    N: 0.0471\n",
      "    S: 0.0448\n",
      "    IY: 0.0437\n",
      "    AH: 0.0374\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.7931\n",
      "    Cluster 1: 0.1223\n",
      "    Cluster 2: 0.0846\n",
      "----------------------------------------\n",
      "Token 18 (Input Phoneme: AA):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0583\n",
      "    N: 0.0421\n",
      "    IY: 0.0399\n",
      "    K: 0.0379\n",
      "    S: 0.0374\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.7539\n",
      "    Cluster 1: 0.1345\n",
      "    Cluster 2: 0.1116\n",
      "----------------------------------------\n",
      "Token 19 (Input Phoneme: AA):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0566\n",
      "    IY: 0.0549\n",
      "    N: 0.0432\n",
      "    S: 0.0382\n",
      "    K: 0.0369\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.7552\n",
      "    Cluster 1: 0.1438\n",
      "    Cluster 2: 0.1009\n",
      "----------------------------------------\n",
      "Token 20 (Input Phoneme: AA):\n",
      "  Top 5 Phoneme Predictions:\n",
      "    T: 0.0495\n",
      "    IY: 0.0436\n",
      "    S: 0.0435\n",
      "    N: 0.0393\n",
      "    AH: 0.0377\n",
      "  Top Prosody Predictions:\n",
      "    Cluster 0: 0.7576\n",
      "    Cluster 1: 0.1366\n",
      "    Cluster 2: 0.1058\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Assume you have access to phoneme_vocab and its inverse mapping\n",
    "id2phoneme = {v: k for k, v in phoneme_vocab.items()}\n",
    "phoneme_logits = outputs.logits[0]  # shape: [seq_len, vocab_size]\n",
    "prosody_logits = outputs.prosody_logits[0]  # shape: [seq_len, prosody_cluster_size]\n",
    "\n",
    "print(\"Top 5 predictions per token:\\n\")\n",
    "\n",
    "for i in range(input_ids.shape[1]):  # loop over tokens in sequence\n",
    "    print(f\"Token {i + 1} (Input Phoneme: {id2phoneme[input_ids[0, i].item()]}):\")\n",
    "\n",
    "    # ==== Phoneme Prediction ====\n",
    "    phoneme_probs = torch.softmax(phoneme_logits[i], dim=-1)\n",
    "    top5_phoneme = torch.topk(phoneme_probs, 5)\n",
    "    print(\"  Top 5 Phoneme Predictions:\")\n",
    "    for j in range(5):\n",
    "        pid = top5_phoneme.indices[j].item()\n",
    "        prob = top5_phoneme.values[j].item()\n",
    "        print(f\"    {id2phoneme[pid]}: {prob:.4f}\")\n",
    "\n",
    "    # ==== Prosody Prediction ====\n",
    "    prosody_probs = torch.softmax(prosody_logits[i], dim=-1)\n",
    "    top5_prosody = torch.topk(prosody_probs, min(5, prosody_probs.size(-1)))\n",
    "    print(\"  Top Prosody Predictions:\")\n",
    "    for j in range(top5_prosody.indices.size(0)):\n",
    "        pid = top5_prosody.indices[j].item()\n",
    "        prob = top5_prosody.values[j].item()\n",
    "        print(f\"    Cluster {pid}: {prob:.4f}\")\n",
    "    \n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f1f90-8e65-40ac-87bd-c86d9f1ee4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
